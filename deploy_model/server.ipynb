{"cells":[{"cell_type":"markdown","metadata":{"id":"p9zuxUjiYCYN"},"source":["# Деплой ML модели\n","\n","И снова здравствуйте! Если вы читаете этот текст, значит вы все сделали верно.\n","\n","Эта лаборатория посвящена развертыванию реальной модели машинного обучения и проверке ее в работе. Более конкретно, вы развернете модель компьютерного зрения, обученную обнаруживать объекты на изображениях. Развертывание модели - это один из последних шагов в жизненном цикле машинного обучения. В этом задании используется предварительно обученная модель под названием [`YOLOV3`](https://pjreddie.com/darknet/yolo /). Эта модель очень удобна по двум причинам: она работает очень быстро и точно.\n","\n","Последовательность шагов / задач, которые необходимо выполнить в этой лаборатории, выглядит следующим образом:\n","1. Проверить датасет изображений, используемый для обнаружения объектов\n","2. Посмотреть саму модель\n","3. Развернуть модель с помощью [`fast API`](https://fastapi.triangolo.com /)"]},{"cell_type":"markdown","metadata":{"id":"NtuXZNEvYCYT"},"source":["## Обнаружение объектов с помощью YOLOV3\n","\n","### Проверка изображений\n","\n","Давайте взглянем на изображения, которые будут переданы в модель YOLOV3. Это даст представление о том, какие типы объектов присутствуют на изображениях. Эти изображения являются частью датасета[`ImageNet`](http://www.image-net.org/index )."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"fGYVyWQzYCYV","executionInfo":{"status":"ok","timestamp":1649089567014,"user_tz":-240,"elapsed":620,"user":{"displayName":"Андрей Милюхин","userId":"06725808120447994223"}}},"outputs":[],"source":["from IPython.display import Image, display"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"id":"q36Goa4KYCYX","executionInfo":{"status":"error","timestamp":1649089569031,"user_tz":-240,"elapsed":13,"user":{"displayName":"Андрей Милюхин","userId":"06725808120447994223"}},"outputId":"b155509f-f551-45c0-8d92-73395869f858"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Displaying image: apple.jpg\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-8a7aec70b8b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nDisplaying image: {image_file}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"images/{image_file}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename)\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0municode_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'images/apple.jpg'"]}],"source":["# Примеры изображений\n","image_files = [\n","    'apple.jpg',\n","    'clock.jpg',\n","    'oranges.jpg',\n","    'car.jpg'\n","]\n","\n","for image_file in image_files:\n","    print(f\"\\nDisplaying image: {image_file}\")\n","    display(Image(filename=f\"images/{image_file}\"))"]},{"cell_type":"markdown","metadata":{"id":"I4gzp02UYCYY"},"source":["### Обзор модели\n","\n","Теперь, когда у вас есть представление об изображениях и присутствующих на них объектах, давайте посмотрим, способна ли модель правильно их обнаруживать и классифицировать.\n","\n","Для этого вы будете использовать [`cvlib`](https://www.cvlib.net /), которая представляет собой очень простую, но мощную библиотеку для обнаружения объектов, использующую [`OpenCV`](https://docs.opencv.org/4.5.1 /) и [`Tensorflow`](https://www.tensorflow.org /).\n","\n","Более конкретно, вы будете использовать [`detect_common_objects`](https://docs.cvlib.net/object_detection /) функция, которая принимает изображение, отформатированное в виде [`numpy array`](https://numpy.org/doc/stable/reference/generated/numpy.array.html ) и возвращает:\n","\n","- `bbox`: список содержащий координаты ограничивающей рамки для обнаруженных объектов. \n","\n","        Пример:\n","    \n","    ```python\n","        [[32, 76, 128, 192], [130, 83, 220, 185]]\n","    ```\n","    \n","\n","- `label`: список меток распознанных объектов.\n","    \n","        Пример:\n","    ```python\n","        ['apple', 'apple']\n","    ```\n","\n","\n","- `conf`: Список коэффициентов достоверности.\n","        Пример:\n","        \n","    ```python\n","        [0.6187325716018677, 0.42835739254951477]\n","    ```\n","    \n","В следующем разделе вы наглядно увидите эти элементы в действии."]},{"cell_type":"markdown","metadata":{"id":"SVCcYhGVYCYa"},"source":["### Создание функции detect_and_draw_box\n","\n","Перед использованием модели создайте каталог, в котором вы можете хранить полученные изображения:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lFWp9ICGYCYc"},"outputs":[],"source":["import os\n","\n","dir_name = \"images_with_boxes\"\n","if not os.path.exists(dir_name):\n","    os.mkdir(dir_name)"]},{"cell_type":"markdown","metadata":{"id":"GS_7F3vpYCYd"},"source":["Давайте определим функцию `detect_and_draw_box`, которая принимает в качестве входных аргументов: **filename** файла в вашей системе, **model** и **confidence level**. С помощью этих входных данных она обнаруживает общие объекты на изображении и сохраняет новое изображение, отображающее ограничительные рамки рядом с обнаруженным объектом.\n","\n","Вы можете спросить себя, почему эта функция получает модель в качестве входного аргумента? Из каких моделей можно выбрать? Ответ заключается в том, что `detect_common_objects` по умолчанию использует модель `yolov3`. Однако существует другой доступный вариант, который намного меньше и требует меньше вычислительной мощности.\n","\n","Это версия `yolov3-tiny`. Как следует из названия модели, эта модель предназначена для ограниченных сред, которые не могут хранить большие модели. При этом возникает естественный компромисс: результаты менее точны, чем у полной модели. Тем не менее, она по-прежнему работает довольно хорошо. В дальнейшем я рекомендую вам придерживаться этой модели, так как она намного меньше обычной \"yolov3\", а загрузка ее предварительно обученных весов занимает меньше времени.\n","\n","Выходные данные модели представляют собой вектор вероятностей присутствия различных объектов на изображении. Последний входной аргумент, уровень достоверности, определяет пороговое значение, которое должна превысить вероятность, чтобы сообщить, что данный объект обнаружен на предоставленном изображении. По умолчанию `detect_common_objects` использует для этого значение 0,5."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z3GJkQD-YCYf"},"outputs":[],"source":["import cv2\n","import cvlib as cv\n","from cvlib.object_detection import draw_bbox\n","\n","\n","def detect_and_draw_box(filename, model=\"yolov3-tiny\", confidence=0.5):\n","    \"\"\"Обнаруживает объекты на изображении и создает новое изображение с ограничивающими рамками.\n","\n","    Аргументы:\n","        filename (str): Имя файла изображения.\n","        model (str): Либо \"yolov3\", либо \"yolov3-tiny\". По умолчанию используется значение \"yolov3-tiny\".\n","        confidence (float, optional): Желаемый уровень достоверности. Значение по умолчанию равно 0,5.\n","    \"\"\"\n","    \n","    # Изображения хранятся в каталоге images/\n","    img_filepath = f'images/{filename}'\n","    \n","    # Считывание изображения в массив numpy\n","    img = cv2.imread(img_filepath)\n","    \n","    # Выполняем обнаружение объекта\n","    bbox, label, conf = cv.detect_common_objects(img, confidence=confidence, model=model)\n","    \n","    # Печать имени файла текущего изображения\n","    print(f\"========================\\nImage processed: {filename}\\n\")\n","    \n","    # Печать обнаруженных объектов с уровнем достоверности\n","    for l, c in zip(label, conf):\n","        print(f\"Detected object: {l} with confidence level of {c}\\n\")\n","    \n","    # Создаем новое изображение, включающее ограничительные рамки\n","    output_image = draw_bbox(img, bbox, label, conf)\n","    \n","    # Сохраняем изображение в каталоге images_with_boxes\n","    cv2.imwrite(f'images_with_boxes/{filename}', output_image)\n","    \n","    # Покажем изображения с ограничивающими рамками\n","    display(Image(f'images_with_boxes/{filename}'))"]},{"cell_type":"markdown","metadata":{"id":"12XeG06YYCYh"},"source":["Давайте попробуем."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YtV-8m7ZYCYi"},"outputs":[],"source":["for image_file in image_files:\n","    detect_and_draw_box(image_file)"]},{"cell_type":"markdown","metadata":{"id":"AfU35Hm4YCYj"},"source":["## Изменение уровня достоверности\n","\n","Похоже, обнаружение объекта прошло довольно успешно. Давайте попробуем на более сложном изображении, содержащем несколько объектов:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Eatn8G7MYCYk"},"outputs":[],"source":["detect_and_draw_box(\"fruits.jpg\")"]},{"cell_type":"markdown","metadata":{"id":"95V3ZpZwYCYl"},"source":["Модель ошибочно классифицировала апельсин как яблоко. Это может показаться странным, поскольку раньше она могла обнаружить одно яблоко, из этого можно предположить, что модель имеет четкое представление о том, как выглядит яблоко.\n","\n","Один из вариантов почему это произошло заключается в том, что модель действительно обнаружила другие фрукты, но с уровнем достоверности ниже 0,5. Давайте проверим, является ли это верной гипотезой:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"linqjOqKYCYm"},"outputs":[],"source":["detect_and_draw_box(\"fruits.jpg\", confidence=0.2)"]},{"cell_type":"markdown","metadata":{"id":"Ss6PfQA_YCYn"},"source":["Снижая уровень достоверности, модель успешно обнаруживает большинство фруктов. Однако, чтобы правильно обнаружить присутствующие объекты, нам пришлось установить очень низкий уровень достоверности. В общем, вы должны быть осторожны при уменьшении или увеличении таких параметров, так как их изменение может привести к нежелательным результатам.\n","\n","Что касается этого конкретного примера, когда апельсин был ошибочно классифицирован как яблоко, он служит напоминанием о том, что эти модели не идеальны, и это следует учитывать при их использовании для производственных задач."]},{"cell_type":"markdown","metadata":{"id":"wckwhRmGYCYo"},"source":["## Развертывание модели с использованием fast API\n","\n","\n","### Размещение вашей модели обнаружения объектов на сервере\n","\n","Теперь, когда вы знаете, как работает модель, пришло время ее развернуть! Разве это не круто?))\n","\n","Прежде чем перейти к развертыванию, давайте кратко рассмотрим некоторые важные концепции и то, как они переводятся в \"fastAPI`. Также создадим каталог для хранения изображений, загружаемых на сервер."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3sNdmdxJYCYp"},"outputs":[],"source":["dir_name = \"images_uploaded\"\n","if not os.path.exists(dir_name):\n","    os.mkdir(dir_name)"]},{"cell_type":"markdown","metadata":{"id":"fNDK5FOkYCYq"},"source":["### Некоторые пояснения к концепции\n","\n","#### Модель клиент-Сервер\n","\n","Когда говорят о **деплое**, обычно подразумевается размещение всего программного обеспечения, необходимого для прогнозирования, на `сервере`. Делая это, \"клиент\" может взаимодействовать с моделью, отправляя `запросы` на сервер.\n","\n","Важная вещь, на которой вам нужно сосредоточиться, заключается в том, что модель машинного обучения находится на сервере, ожидающем, пока клиенты отправят запросы на прогнозирование. Клиент должен предоставить информацию, необходимую модели для того, чтобы сделать прогноз. Имейте в виду, что обычно в одном запросе группируется много прогнозов. Сервер будет использовать предоставленную информацию для возврата прогнозов клиенту, который затем сможет использовать их.\n","\n","Давайте начнем с создания экземпляра класса `Fast API`:\n","\n","```python\n","app = FastAPI()\n","```\n","\n","Следующим шагом будет использование этого экземпляра для создания конечных точек, которые будут обрабатывать логику прогнозирования (подробнее об этом далее). Как только весь код будет на месте, для запуска сервера вам нужно только использовать команду:\n","\n","```python\n","uvicorn.run(app)\n","```\n","\n","Ваш API создан с использованием fast API, но обслуживается он с помощью [`unicorn`](https://www.unicorne.org /), который представляет собой действительно быструю реализацию асинхронного интерфейса шлюза сервера (ASGI). Обе технологии тесно взаимосвязаны, и вам не нужно разбираться в деталях реализации.\n","\n","#### Endpoints\n","\n","Вы можете разместить несколько моделей машинного обучения на одном сервере. Чтобы это сработало, вы можете назначить каждой модели другую \"конечную точку\", чтобы всегда знать, какая модель используется. Конечная точка представлена шаблоном в `URL`. Например, если у вас есть веб-сайт под названием `myawesomemodel.com ` у вас могут быть три разные модели в следующих конечных точках:\n","\n","- `myawesomemodel.com/count-cars/`\n","- `myawesomemodel.com/count-apples/`\n","- `myawesomemodel.com/count-plants/`\n","\n","Каждая модель будет делать то, что предполагает шаблон названия.\n","\n","В fastAPI вы определяете конечную точку, создавая функцию, которая будет обрабатывать всю логику для этой конечной точки и [декорировать](https://www.python.org/dev/peps/pep-0318 /) его с функцией, которая содержит информацию о разрешенном методе HTTP (подробнее об этом далее) и шаблоне в URL, который он будет использовать.\n","\n","В следующем примере показано, как разрешить HTTP-запрос GET для конечной точки \"/my-endpoint\":\n","\n","```python\n","@app.get(\"/my-endpoint\")\n","def handle_endpoint():\n","    ...\n","    ...\n","```\n","\n","\n","#### HTTP запрос\n","\n","Клиент и сервер взаимодействуют друг с другом по протоколу, называемому `HTTP`. Ключевая концепция здесь заключается в том, что при этом общении между клиентом и сервером используются некоторые глаголы для обозначения общих действий. Два очень распространенных глагола - это:\n","\n","- `GET` -> Получает информацию с сервера.\n","- `POST` -> Отправляет серверу информацию, которую он использует для ответа.\n","\n","Если ваш клиент выполняет \"GET-запрос\" к конечной точке сервера, вы получите некоторую информацию от этой конечной точки без необходимости предоставления дополнительной информации. В случае \"POST-запроса\" вы явно сообщаете серверу, что предоставите ему некоторую информацию, которая должна быть обработана каким-либо образом.\n","\n","```python\n","@app.post(\"/my-other-endpoint\")\n","def handle_other_endpoint(param1: int, param2: str):\n","    ...\n","    ...\n","\n","```\n","\n","Для POST запросов функция обработчика содержит параметры. В отличие от GET, запросы POST ожидают, что клиент предоставит серверу некоторую информацию. В этом случае мы указали два параметра: целое число и строку.\n","\n","\n","### ### Почему fastAPI?\n","\n","С помощью fastAPI вы можете очень легко создавать веб-серверы для размещения ваших моделей. Кроме того, эта платформа чрезвычайно быстра и **имеет встроенный клиент, который можно использовать для взаимодействия с сервером**. Чтобы использовать его, вам нужно будет посетить конечную точку \"/docs\", в данном случае это означает посещение http://localhost:8000/docs . Разве это не удобно?\n","\n","Хватит болтовни, погнали!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xmpzDJtHYCYr"},"outputs":[],"source":["import io\n","import uvicorn\n","import numpy as np\n","import nest_asyncio\n","from enum import Enum\n","from fastapi import FastAPI, UploadFile, File, HTTPException\n","from fastapi.responses import StreamingResponse"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PBQnGiLqYCYs"},"outputs":[],"source":["# Присвоите экземпляр класса Fast API переменной \"app\".\n","# Вы будете взаимодействовать со своим api, используя этот экземпляр.\n","app = FastAPI(title='Deploying a ML Model with FastAPI')\n","\n","# Перечислите доступные модели, используя Enum для удобства. Это полезно, когда параметры предопределены.\n","class Model(str, Enum):\n","    yolov3tiny = \"yolov3-tiny\"\n","    yolov3 = \"yolov3\"\n","\n","\n","# Используя @app.get(\"/\"), вы разрешаете методу GET работать для конечной точки /.\n","@app.get(\"/\")\n","def home():\n","    return \"Поздравляю! Ваш API работает так, как надо. А теперь направляйтесь к http://localhost:8000/docs.\"\n","\n","\n","# Эта конечная точка обрабатывает всю логику, необходимую для обнаружения объекта.\n","# Для этого требуется желаемая модель и изображение, на котором выполняется обнаружение объекта.\n","@app.post(\"/predict\") \n","def prediction(model: Model, file: UploadFile = File(...)):\n","\n","    # 1. ПРОВЕРКА ВХОДНОГО ФАЙЛА\n","    filename = file.filename\n","    fileExtension = filename.split(\".\")[-1] in (\"jpg\", \"jpeg\", \"png\")\n","    if not fileExtension:\n","        raise HTTPException(status_code=415, detail=\"Unsupported file provided.\")\n","    \n","    # 2. ПРЕОБРАЗОВАНИЕ НЕОБРАБОТАННОГО ИЗОБРАЖЕНИЯ В изображение CV2 \n","    \n","    # Считывание изображения в виде потока байтов\n","    image_stream = io.BytesIO(file.file.read())\n","    \n","    # Запускаем поток с самого начала (нулевая позиция)\n","    image_stream.seek(0)\n","    \n","    # Запишем поток байтов в массив numpy\n","    file_bytes = np.asarray(bytearray(image_stream.read()), dtype=np.uint8)\n","    \n","    # Декодируем массив numpy в изображение CV2 \n","    image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)\n","    \n","    \n","    # 3. ЗАПУСТИТЬ МОДЕЛЬ ОБНАРУЖЕНИЯ ОБЪЕКТОВ\n","    \n","    # Запустим обнаружение объектов\n","    bbox, label, conf = cv.detect_common_objects(image, model=model)\n","    \n","    # Создадим изображение, включающее ограничительные рамки и метки\n","    output_image = draw_bbox(image, bbox, label, conf)\n","    \n","    # Сохраним его в папке на сервере\n","    cv2.imwrite(f'images_uploaded/{filename}', output_image)\n","    \n","    \n","    # 4. ПЕРЕДАДИМ ОТВЕТ ОБРАТНО КЛИЕНТУ\n","    \n","    # Откроем сохраненное изображение для чтения в двоичном формате\n","    file_image = open(f'images_uploaded/{filename}', mode=\"rb\")\n","    \n","    # Возвращаем изображение в виде потока с указанием типа файла\n","    return StreamingResponse(file_image, media_type=\"image/jpeg\")"]},{"cell_type":"markdown","metadata":{"id":"r5bKEu-EYCYt"},"source":["Запустив следующую ячейку, вы запустите сервер!\n","\n","Это приведет к блокировке текущего ноутбука (никакие ячейки / код не могут выполняться) до тех пор, пока вы вручную не перезапустите ядро. Вы можете сделать это, нажав на вкладку \"Kernel\", а затем на `Interrupt`. Вы также можете войти в командный режим Jupiter, нажав клавишу \"ESC\" и дважды нажав клавишу \"I\"."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-hCHzUw8YCYu"},"outputs":[],"source":["# Позволяем запустить сервер в этой интерактивной среде\n","nest_asyncio.apply()\n","\n","# Хост зависит от выбранной вами настройки (docker или virtualenv)\n","host = \"0.0.0.0\" if os.getenv(\"DOCKER-SETUP\") else \"127.0.0.1\"\n","\n","# Запускаем сервер!    \n","uvicorn.run(app, host=host, port=8000)"]},{"cell_type":"markdown","metadata":{"id":"Tca_kQKbYCYv"},"source":["Сервер запущен! Направляйтесь к [http://localhost:8000 /](http://localhost:8000 /), чтобы увидеть его в действии.\n","\n","**Попробуйте отправить изображение** и посмотрите, как ваш API может обнаруживать объекты и возвращать новое изображение, содержащее ограничительные рамки рядом с метками обнаруженных объектов. **Вы можете сделать это, посетив [http://localhost:8000/docs ](http://localhost:8000/docs ), чтобы открыть встроенный клиент fastAPI.**\n","\n","При этом вы получите экран, который должен выглядеть так, как показано ниже, следуйте инструкциям далее:"]},{"cell_type":"markdown","metadata":{"id":"h31pIFAbYCYv"},"source":["Нажмите на верхнюю часть конечной точки \"/predict\", и станут видны дополнительные параметры:"]},{"cell_type":"markdown","metadata":{"id":"rOgQqpK8YCYw"},"source":["![image.png](attachment:image.png)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"A_kaC69RYCYx"},"source":["Чтобы протестировать свой сервер, нажмите на кнопку **Try it out**."]},{"cell_type":"markdown","metadata":{"id":"NpOXEXH6YCYx"},"source":["![image.png](attachment:image.png)"]},{"cell_type":"markdown","metadata":{"id":"hSZiCLOiYCYx"},"source":["Вы можете выбрать модель из поля **model** (если вы выберете полную модель YOLO, сервер будет заблокирован до тех пор, пока не будут загружены веса для этой модели) и **file**, который должен быть изображением, в котором вы хотите, чтобы сервер обнаруживал объекты.\n","\n","**Отправьте изображение** из вашей локальной файловой системы, нажав кнопку **Choose File**, затем нажмите синюю кнопку **Execute**, чтобы отправить HTTP-запрос на сервер. После этого **прокрутите страницу вниз, и вы увидите ответ от сервера**. Довольно круто, правда?"]},{"cell_type":"markdown","metadata":{"id":"kTlAZXezYCYy"},"source":["![image.png](attachment:image.png)"]},{"cell_type":"markdown","metadata":{"id":"jl7A2mX3YCYy"},"source":["**Попробуйте разные изображения!** Вы можете использовать те, которые предоставлены в этом задании, или свои собственные. Поскольку модель использует уровень достоверности по умолчанию, равный 0,5, обнаружение некоторых объектов может быть не всегда успешным.\n","\n","Кроме того, попробуйте отправить файлы, не содержащие изображений, и посмотрите, как сервер отреагирует на это."]},{"cell_type":"markdown","metadata":{"id":"SVjJXaOLYCYz"},"source":["## Использование вашей модели в другом клиенте\n","\n","Удивительно, что fast API позволяет вам взаимодействовать с вашим API через его встроенный клиент. Однако вы можете задаться вопросом, как вы можете взаимодействовать со своим API, используя обычный код, а не какой-то пользовательский интерфейс.\n","\n","Для этого во второй части задания представлен минимальный клиент на Python. Для того, чтобы посмотреть как он работает **оставьте сервер работающим (не прерывайте ядро и не закрывайте это окно)** и откройте ноутбук `client.ipynb`. Для этого вы можете открыть вкладку Браузера файлов на боковой панели, расположенной слева от окна, и дважды щелкнуть по `client.ipynb`. Если вы не видите отдельную вкладку для каждого файла (что очень полезно для перемещения между ними), возможно, у вас включен режим \"Simple Interface\" (он же Одностраничный). Чтобы отключить его, вы можете перейти на вкладку \"View\" и отключить его."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"name":"server.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}